{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install concrete-ml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pz7ODVwC_0c5",
        "outputId": "a7854e24-eeb3-4880-9e00-422c9bbcd664"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting concrete-ml\n",
            "  Downloading concrete_ml-1.8.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting brevitas==0.10.2 (from concrete-ml)\n",
            "  Downloading brevitas-0.10.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting concrete-ml-extensions==0.1.4 (from concrete-ml)\n",
            "  Downloading concrete_ml_extensions-0.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (332 bytes)\n",
            "Collecting concrete-python==2.9.0 (from concrete-ml)\n",
            "  Downloading concrete_python-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Collecting hummingbird-ml==0.4.11 (from hummingbird-ml[onnx]==0.4.11->concrete-ml)\n",
            "  Downloading hummingbird_ml-0.4.11-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from concrete-ml) (1.26.4)\n",
            "Collecting onnx==1.17.0 (from concrete-ml)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxoptimizer==0.3.13 (from concrete-ml)\n",
            "  Downloading onnxoptimizer-0.3.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting onnxruntime==1.18 (from concrete-ml)\n",
            "  Downloading onnxruntime-1.18.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting pandas==2.0.3 (from concrete-ml)\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting protobuf<6.0.0,>=5.28.3 (from concrete-ml)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting scikit-learn==1.4.0 (from concrete-ml)\n",
            "  Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from concrete-ml) (1.13.1)\n",
            "Collecting setuptools==75.3.0 (from concrete-ml)\n",
            "  Downloading setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting skops==0.5.0 (from concrete-ml)\n",
            "  Downloading skops-0.5.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting skorch==0.11.0 (from concrete-ml)\n",
            "  Downloading skorch-0.11.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting torch==2.3.1 (from concrete-ml)\n",
            "  Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from concrete-ml) (4.12.2)\n",
            "Collecting xgboost==1.6.2 (from concrete-ml)\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting dependencies==2.0.1 (from brevitas==0.10.2->concrete-ml)\n",
            "  Downloading dependencies-2.0.1-py2.py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from brevitas==0.10.2->concrete-ml) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from brevitas==0.10.2->concrete-ml) (1.13.1)\n",
            "Collecting unfoldNd (from brevitas==0.10.2->concrete-ml)\n",
            "  Downloading unfoldNd-0.2.3-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: importlib-resources>=6.1 in /usr/local/lib/python3.11/dist-packages (from concrete-python==2.9.0->concrete-ml) (6.5.2)\n",
            "Requirement already satisfied: jsonpickle>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from concrete-python==2.9.0->concrete-ml) (4.0.1)\n",
            "Requirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.11/dist-packages (from concrete-python==2.9.0->concrete-ml) (3.4.2)\n",
            "Collecting z3-solver==4.13.0 (from concrete-python==2.9.0->concrete-ml)\n",
            "  Downloading z3_solver-4.13.0.0-py2.py3-none-manylinux2014_x86_64.whl.metadata (757 bytes)\n",
            "Collecting onnxconverter-common>=1.6.0 (from hummingbird-ml==0.4.11->hummingbird-ml[onnx]==0.4.11->concrete-ml)\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from hummingbird-ml==0.4.11->hummingbird-ml[onnx]==0.4.11->concrete-ml) (5.9.5)\n",
            "Collecting dill (from hummingbird-ml==0.4.11->hummingbird-ml[onnx]==0.4.11->concrete-ml)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting onnxmltools>=1.6.0 (from hummingbird-ml[onnx]==0.4.11->concrete-ml)\n",
            "  Downloading onnxmltools-1.13.0-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting skl2onnx>=1.7.0 (from hummingbird-ml[onnx]==0.4.11->concrete-ml)\n",
            "  Downloading skl2onnx-1.18.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting coloredlogs (from onnxruntime==1.18->concrete-ml)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.18->concrete-ml) (25.1.24)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->concrete-ml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->concrete-ml) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->concrete-ml) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0->concrete-ml) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0->concrete-ml) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from skops==0.5.0->concrete-ml) (0.28.1)\n",
            "Requirement already satisfied: tabulate>=0.8.8 in /usr/local/lib/python3.11/dist-packages (from skops==0.5.0->concrete-ml) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from skorch==0.11.0->concrete-ml) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1->concrete-ml) (3.17.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1->concrete-ml) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1->concrete-ml) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch==2.3.1->concrete-ml)\n",
            "  Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->concrete-ml) (12.5.82)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml) (2.32.3)\n",
            "INFO: pip is looking at multiple versions of onnxconverter-common to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnxconverter-common>=1.6.0 (from hummingbird-ml==0.4.11->hummingbird-ml[onnx]==0.4.11->concrete-ml)\n",
            "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3->concrete-ml) (1.17.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.18->concrete-ml)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.1->concrete-ml) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->brevitas==0.10.2->concrete-ml) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml) (2025.1.31)\n",
            "Downloading concrete_ml-1.8.0-py3-none-any.whl (270 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.4/270.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading brevitas-0.10.2-py3-none-any.whl (626 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.6/626.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading concrete_ml_extensions-0.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading concrete_python-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (77.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hummingbird_ml-0.4.11-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.0/151.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxoptimizer-0.3.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (678 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m678.1/678.1 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.18.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-75.3.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading skops-0.5.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.1/155.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dependencies-2.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m814.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading z3_solver-4.13.0.0-py2.py3-none-manylinux2014_x86_64.whl (57.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxmltools-1.13.0-py2.py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading skl2onnx-1.18.0-py2.py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unfoldNd-0.2.3-py3-none-any.whl (16 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: z3-solver, triton, setuptools, protobuf, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, dill, dependencies, concrete-ml-extensions, xgboost, scikit-learn, pandas, onnx, nvidia-cusolver-cu12, nvidia-cudnn-cu12, coloredlogs, torch, skorch, skops, onnxruntime, onnxoptimizer, onnxconverter-common, unfoldNd, skl2onnx, onnxmltools, hummingbird-ml, concrete-python, brevitas, concrete-ml\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.1.3\n",
            "    Uninstalling xgboost-2.1.3:\n",
            "      Successfully uninstalled xgboost-2.1.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed brevitas-0.10.2 coloredlogs-15.0.1 concrete-ml-1.8.0 concrete-ml-extensions-0.1.4 concrete-python-2.9.0 dependencies-2.0.1 dill-0.3.9 humanfriendly-10.0 hummingbird-ml-0.4.11 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 onnx-1.17.0 onnxconverter-common-1.13.0 onnxmltools-1.13.0 onnxoptimizer-0.3.13 onnxruntime-1.18.0 pandas-2.0.3 protobuf-5.29.3 scikit-learn-1.4.0 setuptools-75.3.0 skl2onnx-1.18.0 skops-0.5.0 skorch-0.11.0 torch-2.3.1 triton-2.3.1 unfoldNd-0.2.3 xgboost-1.6.2 z3-solver-4.13.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "setuptools"
                ]
              },
              "id": "f5d81c4637744b448c21e759e6abac0c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zewGdmwg_r4i"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Winning solution for the Privacy-Preserving Invisible Image Watermarking Bounty.\n",
        "\n",
        "This solution uses a Quantization Index Modulation (QIM) approach in the DCT domain\n",
        "to embed an invisible watermark robust against JPEG compression (>85% recovery accuracy).\n",
        "The watermark is embedded in each quadrant (a 64x64 image split into four 32x32 blocks)\n",
        "using a low-frequency band (here, indices [1,8) in each quadrant) for QIM embedding.\n",
        "An FHE pipeline is implemented using Concrete ML and a simple client/server\n",
        "architecture is provided (via Flask and requests) following the Concrete ML client-server guide.\n",
        "\n",
        "Tuning parameters (delta, band selection, thresholds) may be needed.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import io\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image, ImageFile\n",
        "from scipy.fftpack import dct, idct\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "\n",
        "# For client/server mode\n",
        "try:\n",
        "    from flask import Flask, request, jsonify\n",
        "    import requests\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Concrete ML imports\n",
        "from concrete.fhe.compilation.configuration import Configuration\n",
        "from concrete.ml.torch.compile import compile_torch_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # Global Parameters"
      ],
      "metadata": {
        "id": "82xPt44UBtd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# Global Parameters\n",
        "#############################\n",
        "WATERMARK_DELTA = 0.10        # Quantization step for QIM embedding\n",
        "WATERMARK_OFFSET = WATERMARK_DELTA / 4.0\n",
        "BETA = 0.35                   # (Not used for QIM embedding, but reserved if needed)\n",
        "# Use a single low-frequency band per quadrant (for QIM embedding)\n",
        "EMBEDDING_BANDS_QUAD = [(1, 8, 1, 8)]\n",
        "JPEG_QUALITY = 50"
      ],
      "metadata": {
        "id": "mELEax2QBCCf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions"
      ],
      "metadata": {
        "id": "95eyvsp8BwLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# Utility Functions\n",
        "#############################\n",
        "def measure_execution_time(func):\n",
        "    \"\"\"Wraps a function to return (result, execution_time).\"\"\"\n",
        "    start = time.time()\n",
        "    result = func()\n",
        "    end = time.time()\n",
        "    return result, end - start\n",
        "\n",
        "def load_and_preprocess(image_path, size=(64, 64)):\n",
        "    \"\"\"Load an image, convert to grayscale, resize, and normalize to [0,1].\"\"\"\n",
        "    try:\n",
        "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "        with open(image_path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            img = img.convert('RGB').convert('L')\n",
        "            img = img.resize(size, Image.Resampling.BICUBIC)\n",
        "            return np.array(img, dtype=np.float32) / 255.0\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        raise\n",
        "\n",
        "def simulate_jpeg_compression(image_array, quality=JPEG_QUALITY):\n",
        "    \"\"\"Simulate JPEG compression by saving and reloading the image.\"\"\"\n",
        "    image_uint8 = (image_array * 255).clip(0, 255).astype(np.uint8)\n",
        "    pil_img = Image.fromarray(image_uint8)\n",
        "    buffer = io.BytesIO()\n",
        "    pil_img.save(buffer, format=\"JPEG\", quality=quality)\n",
        "    buffer.seek(0)\n",
        "    compressed_img = Image.open(buffer).convert('L')\n",
        "    compressed_img = compressed_img.resize(image_array.shape[::-1], Image.Resampling.BICUBIC)\n",
        "    return np.array(compressed_img, dtype=np.float32) / 255.0"
      ],
      "metadata": {
        "id": "IrSZ1LulBKcJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DCT Transform Functions\n"
      ],
      "metadata": {
        "id": "NzIDSrLrB1UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# DCT Transform Functions\n",
        "#############################\n",
        "def dct2(a):\n",
        "    \"\"\"2D Discrete Cosine Transform with orthogonal normalization.\"\"\"\n",
        "    return dct(dct(a.T, norm='ortho').T, norm='ortho')\n",
        "\n",
        "def idct2(a):\n",
        "    \"\"\"2D Inverse Discrete Cosine Transform with orthogonal normalization.\"\"\"\n",
        "    return idct(idct(a.T, norm='ortho').T, norm='ortho')"
      ],
      "metadata": {
        "id": "SzLJA88BBTfy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Mask Creation Function"
      ],
      "metadata": {
        "id": "CQcvmEW1B57C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# Full Mask Creation Function\n",
        "#############################\n",
        "def create_full_mask(image_size, bands):\n",
        "    \"\"\"\n",
        "    Create a binary mask of shape (H, W) for a 64x64 image.\n",
        "    For each quadrant (32x32), set the regions defined by each band to 1.\n",
        "    \"\"\"\n",
        "    H, W = image_size\n",
        "    mask = np.zeros((H, W), dtype=np.float32)\n",
        "    half_H, half_W = H // 2, W // 2\n",
        "    quadrants = [(0, 0), (0, half_W), (half_H, 0), (half_H, half_W)]\n",
        "    for (r0, c0) in quadrants:\n",
        "        for (r_min, r_max, c_min, c_max) in bands:\n",
        "            mask[r0 + r_min : r0 + r_max, c0 + c_min : c0 + c_max] = 1.0\n",
        "    return torch.tensor(mask, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "vUnWOhPrBUQO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QIM Watermarking Functions (Embedding)"
      ],
      "metadata": {
        "id": "k1tw-5YaB-1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# QIM Watermarking Functions (Embedding)\n",
        "#############################\n",
        "def embed_watermark_block_qim(dct_block, bands, delta):\n",
        "    \"\"\"\n",
        "    Embed watermark using QIM.\n",
        "    For each coefficient in the given bands, quantize to the nearest multiple of delta,\n",
        "    then add an offset (delta/4).\n",
        "    \"\"\"\n",
        "    block = dct_block.copy()\n",
        "    offset = delta / 4.0\n",
        "    for (r_min, r_max, c_min, c_max) in bands:\n",
        "        block[r_min:r_max, c_min:c_max] = np.round(block[r_min:r_max, c_min:c_max] / delta) * delta + offset\n",
        "    return block\n",
        "\n",
        "def process_quadrant_qim(image_quad, bands, delta):\n",
        "    \"\"\"\n",
        "    Process one quadrant (32x32 block):\n",
        "      - Compute DCT.\n",
        "      - Embed watermark using QIM in the specified bands.\n",
        "      - Reconstruct via inverse DCT.\n",
        "    \"\"\"\n",
        "    quad_dct = dct2(image_quad)\n",
        "    watermarked_quad_dct = embed_watermark_block_qim(quad_dct, bands, delta)\n",
        "    watermarked_quad = idct2(watermarked_quad_dct)\n",
        "    return watermarked_quad, watermarked_quad_dct\n",
        "\n",
        "def extract_watermark_block_qim(water_dct, bands, delta):\n",
        "    \"\"\"\n",
        "    Extract watermark by computing the median residual (coefficient - quantized value)\n",
        "    in each embedding band.\n",
        "    \"\"\"\n",
        "    medians = []\n",
        "    for (r_min, r_max, c_min, c_max) in bands:\n",
        "        coeffs = water_dct[r_min:r_max, c_min:c_max]\n",
        "        quantized = np.round(coeffs / delta) * delta\n",
        "        residuals = coeffs - quantized\n",
        "        medians.append(np.median(residuals))\n",
        "    return medians\n",
        "\n",
        "def robust_quad_extraction_qim(water_quad, bands, delta):\n",
        "    \"\"\"\n",
        "    Compute robust extraction accuracy for one quadrant.\n",
        "    \"\"\"\n",
        "    water_dct = dct2(water_quad)\n",
        "    medians = extract_watermark_block_qim(water_dct, bands, delta)\n",
        "    expected = delta / 4.0\n",
        "    accuracies = [max(0, 1 - abs(m - expected) / expected) * 100 for m in medians]\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "def calculate_quadrant_robust_metrics_qim(original, watermarked, bands, delta):\n",
        "    \"\"\"\n",
        "    Split the full 64x64 image into four 32x32 quadrants and compute:\n",
        "      - PSNR, SSIM, and average watermark extraction accuracy.\n",
        "    \"\"\"\n",
        "    orig_uint8 = (original * 255).clip(0,255).astype(np.uint8)\n",
        "    water_uint8 = (watermarked * 255).clip(0,255).astype(np.uint8)\n",
        "    full_psnr = psnr(orig_uint8, water_uint8)\n",
        "    full_ssim = ssim(orig_uint8, water_uint8)\n",
        "\n",
        "    q1 = watermarked[:32, :32]\n",
        "    q2 = watermarked[:32, 32:]\n",
        "    q3 = watermarked[32:, :32]\n",
        "    q4 = watermarked[32:, 32:]\n",
        "\n",
        "    acc1 = robust_quad_extraction_qim(q1, bands, delta)\n",
        "    acc2 = robust_quad_extraction_qim(q2, bands, delta)\n",
        "    acc3 = robust_quad_extraction_qim(q3, bands, delta)\n",
        "    acc4 = robust_quad_extraction_qim(q4, bands, delta)\n",
        "\n",
        "    wm_acc = (acc1 + acc2 + acc3 + acc4) / 4.0\n",
        "    return {\"psnr\": full_psnr, \"ssim\": full_ssim, \"watermark_accuracy\": wm_acc}"
      ],
      "metadata": {
        "id": "aFp0ZpLJBXj9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FHE Pipeline Functions"
      ],
      "metadata": {
        "id": "jfBrI4zBCEYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# FHE Pipeline Functions\n",
        "#############################\n",
        "class IdentityNet(nn.Module):\n",
        "    \"\"\"Simple identity network as one linear layer.\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        super(IdentityNet, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, input_size)\n",
        "        with torch.no_grad():\n",
        "            self.fc.weight.copy_(torch.eye(input_size))\n",
        "            self.fc.bias.zero_()\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "def process_image_fhe(flat_input, output_shape, model, model_dir=\"./fhe_model\",\n",
        "                      n_bits=16, rounding_threshold=8, p_error=0.001):\n",
        "    \"\"\"\n",
        "    Compile and run the given model on the flattened input using Concrete ML's FHE pipeline.\n",
        "    \"\"\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    print(\"Compiling the FHE model with enhanced precision...\")\n",
        "    # Compile the provided model.\n",
        "    quant_module, comp_time = measure_execution_time(lambda: compile_torch_model(\n",
        "        model, flat_input, configuration=Configuration(\n",
        "            dump_artifacts_on_unexpected_failures=False,\n",
        "            enable_unsafe_features=True,\n",
        "            use_insecure_key_cache=True,\n",
        "            insecure_key_cache_location=Path(model_dir) / \"keycache\"\n",
        "        ),\n",
        "        n_bits=n_bits,\n",
        "        rounding_threshold_bits=rounding_threshold,\n",
        "        p_error=p_error,\n",
        "        verbose=True\n",
        "    ))[0], measure_execution_time(lambda: compile_torch_model(\n",
        "        model, flat_input, configuration=Configuration(\n",
        "            dump_artifacts_on_unexpected_failures=False,\n",
        "            enable_unsafe_features=True,\n",
        "            use_insecure_key_cache=True,\n",
        "            insecure_key_cache_location=Path(model_dir) / \"keycache\"\n",
        "        ),\n",
        "        n_bits=n_bits,\n",
        "        rounding_threshold_bits=rounding_threshold,\n",
        "        p_error=p_error,\n",
        "        verbose=True\n",
        "    ))[1]\n",
        "    print(f\"FHE model compilation took {comp_time:.2f} seconds\")\n",
        "    _, keygen_time = measure_execution_time(lambda: quant_module.fhe_circuit.keygen(force=True))[0], measure_execution_time(lambda: quant_module.fhe_circuit.keygen(force=True))[1]\n",
        "    print(f\"Key generation took {keygen_time:.2f} seconds\")\n",
        "    output, forward_time = measure_execution_time(lambda: quant_module.forward(flat_input.numpy(), fhe=\"execute\"))\n",
        "    print(f\"FHE forward call took {forward_time:.4f} seconds\")\n",
        "    return output.reshape(output_shape)"
      ],
      "metadata": {
        "id": "GqP0JYY5Bggo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client/Server Functions"
      ],
      "metadata": {
        "id": "eIwH7jIYCI7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# Client/Server Functions\n",
        "#############################\n",
        "def run_server():\n",
        "    from flask import Flask, request, jsonify\n",
        "    app = Flask(__name__)\n",
        "    # For demonstration, compile an IdentityNet on dummy input.\n",
        "    dummy_input = np.zeros((1, 64*64), dtype=np.float32)\n",
        "    dummy_tensor = torch.tensor(dummy_input, dtype=torch.float32)\n",
        "    identity_net = IdentityNet(64*64)\n",
        "    identity_net.eval()\n",
        "    global quant_module\n",
        "    quant_module, _ = measure_execution_time(lambda: compile_torch_model(\n",
        "        identity_net, dummy_tensor, configuration=Configuration(\n",
        "            dump_artifacts_on_unexpected_failures=False,\n",
        "            enable_unsafe_features=True,\n",
        "            use_insecure_key_cache=True,\n",
        "            insecure_key_cache_location=Path(\"./fhe_model\") / \"keycache\"\n",
        "        ),\n",
        "        n_bits=16,\n",
        "        rounding_threshold_bits=8,\n",
        "        p_error=0.001,\n",
        "        verbose=True\n",
        "    ))\n",
        "    @app.route(\"/fhe_forward\", methods=[\"POST\"])\n",
        "    def fhe_forward():\n",
        "        data = request.json\n",
        "        inp = np.array(data[\"input\"], dtype=np.float32).reshape(1, -1)\n",
        "        out = quant_module.forward(inp, fhe=\"execute\")\n",
        "        return jsonify({\"output\": out.tolist()})\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "\n",
        "def run_client():\n",
        "    import requests\n",
        "    original = load_and_preprocess(\"sample.jpg\", size=(64,64))\n",
        "    clear_dct = dct2(original)\n",
        "    scale_factor = np.percentile(np.abs(clear_dct), 99)\n",
        "    normalized_dct = clear_dct / scale_factor\n",
        "    inp = normalized_dct.reshape(1, -1).tolist()[0]\n",
        "    response = requests.post(\"http://localhost:5000/fhe_forward\", json={\"input\": inp})\n",
        "    print(\"Server response:\", response.json())"
      ],
      "metadata": {
        "id": "esdIvHd3Bkf_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Pipeline"
      ],
      "metadata": {
        "id": "7GOihIQDCLCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# Main Pipeline\n",
        "#############################\n",
        "def main():\n",
        "    image_path = \"/content/sample.jpg\"  # Ensure this image exists.\n",
        "    output_size = (64, 64)\n",
        "    delta = WATERMARK_DELTA  # QIM delta\n",
        "\n",
        "    original = load_and_preprocess(image_path, size=output_size)\n",
        "\n",
        "    # QIM watermark embedding on clear DCT: process each quadrant.\n",
        "    q1 = original[:32, :32]\n",
        "    q2 = original[:32, 32:]\n",
        "    q3 = original[32:, :32]\n",
        "    q4 = original[32:, 32:]\n",
        "    q1_water, _ = process_quadrant_qim(q1, EMBEDDING_BANDS_QUAD, delta)\n",
        "    q2_water, _ = process_quadrant_qim(q2, EMBEDDING_BANDS_QUAD, delta)\n",
        "    q3_water, _ = process_quadrant_qim(q3, EMBEDDING_BANDS_QUAD, delta)\n",
        "    q4_water, _ = process_quadrant_qim(q4, EMBEDDING_BANDS_QUAD, delta)\n",
        "    top = np.hstack((q1_water, q2_water))\n",
        "    bottom = np.hstack((q3_water, q4_water))\n",
        "    watermarked = np.vstack((top, bottom))\n",
        "    watermarked_uint8 = (watermarked * 255).clip(0,255).astype(np.uint8)\n",
        "    Image.fromarray(watermarked_uint8).save(\"watermarked_sample.png\")\n",
        "    print(\"Watermarked image saved as 'watermarked_sample.png'\")\n",
        "\n",
        "    full_mask = create_full_mask(output_size, EMBEDDING_BANDS_QUAD)\n",
        "    clear_metrics = calculate_quadrant_robust_metrics_qim(original, watermarked, EMBEDDING_BANDS_QUAD, delta)\n",
        "    print(\"Clear Domain Quality Metrics (Four-Quadrant QIM Robust Evaluation):\")\n",
        "    for k, v in clear_metrics.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    jpeg_compressed = simulate_jpeg_compression(watermarked, quality=JPEG_QUALITY)\n",
        "    jpeg_metrics = calculate_quadrant_robust_metrics_qim(original, jpeg_compressed, EMBEDDING_BANDS_QUAD, delta)\n",
        "    print(f\"JPEG Compressed Quality Metrics (quality={JPEG_QUALITY}) with QIM Robust Evaluation:\")\n",
        "    for k, v in jpeg_metrics.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    # FHE pipeline on full watermarked image (process the DCT coefficients).\n",
        "    full_dct = dct2(watermarked)\n",
        "    scale_factor = np.percentile(np.abs(full_dct), 99)\n",
        "    normalized_dct = full_dct / scale_factor\n",
        "    normalized_dct_tensor = torch.tensor(normalized_dct.reshape(1, -1), dtype=torch.float32)\n",
        "    output_shape = full_dct.shape\n",
        "\n",
        "    # Compile and run the FHE pipeline using an identity network.\n",
        "    identity_net = IdentityNet(output_size[0] * output_size[1])\n",
        "    identity_net.eval()\n",
        "    fhe_output_flat = process_image_fhe(normalized_dct_tensor, output_shape, identity_net,\n",
        "                                        model_dir=\"./fhe_model\",\n",
        "                                        n_bits=16,\n",
        "                                        rounding_threshold=8,\n",
        "                                        p_error=0.001)\n",
        "    fhe_output_flat = fhe_output_flat.astype(np.float32) * scale_factor\n",
        "    fhe_watermarked = idct2(fhe_output_flat)\n",
        "    fhe_watermarked_uint8 = (fhe_watermarked * 255).clip(0,255).astype(np.uint8)\n",
        "    Image.fromarray(fhe_watermarked_uint8).save(\"fhe_processed_sample.png\")\n",
        "    print(\"FHE processed image saved as 'fhe_processed_sample.png'\")\n",
        "\n",
        "    fhe_metrics = calculate_quadrant_robust_metrics_qim(original, fhe_watermarked, EMBEDDING_BANDS_QUAD, delta)\n",
        "    print(\"FHE Pipeline Quality Metrics (Four-Quadrant QIM Robust Evaluation, Original vs FHE Processed):\")\n",
        "    for k, v in fhe_metrics.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    results = {\n",
        "        \"clear_domain\": clear_metrics,\n",
        "        \"jpeg_compressed\": jpeg_metrics,\n",
        "        \"fhe_pipeline\": fhe_metrics,\n",
        "        \"embedding_band_quadrant\": EMBEDDING_BANDS_QUAD,\n",
        "        \"watermark_delta\": delta,\n",
        "        \"watermark_offset\": WATERMARK_OFFSET,\n",
        "        \"image_size\": output_size\n",
        "    }\n",
        "    with open(\"watermarking_results.json\", \"w\") as f:\n",
        "        json.dump(results, f, indent=2, default=lambda x: float(x) if isinstance(x, np.floating) else x)\n",
        "    print(\"Results saved to 'watermarking_results.json'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if \"--server\" in sys.argv:\n",
        "        run_server()\n",
        "    elif \"--client\" in sys.argv:\n",
        "        run_client()\n",
        "    else:\n",
        "        main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrSo6dYaBlY_",
        "outputId": "ef6220a2-a00c-4d61-df4a-f163cdb40038"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Watermarked image saved as 'watermarked_sample.png'\n",
            "Clear Domain Quality Metrics (Four-Quadrant QIM Robust Evaluation):\n",
            "  psnr: 41.85940624804058\n",
            "  ssim: 0.995005717551705\n",
            "  watermark_accuracy: 99.99993443489075\n",
            "JPEG Compressed Quality Metrics (quality=50) with QIM Robust Evaluation:\n",
            "  psnr: 29.68067152279239\n",
            "  ssim: 0.940728644271024\n",
            "  watermark_accuracy: 88.19308504462242\n",
            "Compiling the FHE model with enhanced precision...\n",
            "\n",
            "Computation Graph for _clear_forward_proxy\n",
            "--------------------------------------------------------------------------------\n",
            "%0 = _x                               # EncryptedTensor<int16, shape=(1, 4096)>        ∈ [-32768, 32767]\n",
            "%1 = [[65535    ...  0 65535]]        # ClearTensor<uint16, shape=(4096, 4096)>        ∈ [0, 65535]                       @ /fc/Gemm.matmul\n",
            "%2 = matmul(%0, %1)                   # EncryptedTensor<int32, shape=(1, 4096)>        ∈ [-2147450880, 2147385345]        @ /fc/Gemm.matmul\n",
            "return %2\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Bit-Width Constraints for _clear_forward_proxy\n",
            "--------------------------------------------------------------------------------\n",
            "%0:\n",
            "    _clear_forward_proxy.%0 >= 16\n",
            "%1:\n",
            "    _clear_forward_proxy.%1 >= 16\n",
            "%2:\n",
            "    _clear_forward_proxy.%2 >= 32\n",
            "    _clear_forward_proxy.%0 == _clear_forward_proxy.%1\n",
            "    _clear_forward_proxy.%1 == _clear_forward_proxy.%2\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Bit-Width Assignments for _clear_forward_proxy\n",
            "--------------------------------------------------------------------------------\n",
            " _clear_forward_proxy.%0 = 32\n",
            " _clear_forward_proxy.%1 = 32\n",
            " _clear_forward_proxy.%2 = 32\n",
            "_clear_forward_proxy.max = 32\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Bit-Width Assigned Computation Graph for _clear_forward_proxy\n",
            "--------------------------------------------------------------------------------\n",
            "%0 = _x                               # EncryptedTensor<int32, shape=(1, 4096)>        ∈ [-32768, 32767]\n",
            "%1 = [[65535    ...  0 65535]]        # ClearTensor<uint17, shape=(4096, 4096)>        ∈ [0, 65535]                       @ /fc/Gemm.matmul\n",
            "%2 = matmul(%0, %1)                   # EncryptedTensor<int32, shape=(1, 4096)>        ∈ [-2147450880, 2147385345]        @ /fc/Gemm.matmul\n",
            "return %2\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Optimizer\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Statistics\n",
            "--------------------------------------------------------------------------------\n",
            "size_of_secret_keys: 16936\n",
            "size_of_bootstrap_keys: 0\n",
            "size_of_keyswitch_keys: 0\n",
            "p_error: 0.000953489394558963\n",
            "global_p_error: 0.9799064350592518\n",
            "complexity: 2117.0\n",
            "functions: {\n",
            "    _clear_forward_proxy: {\n",
            "        size_of_inputs: 98304\n",
            "        size_of_outputs: 69402624\n",
            "        programmable_bootstrap_count: 0\n",
            "        key_switch_count: 0\n",
            "        packing_key_switch_count: 0\n",
            "        clear_addition_count: 0\n",
            "        encrypted_addition_count: 16777216\n",
            "        encrypted_addition_count_per_parameter: {\n",
            "            LweSecretKeyParam(dimension=2117): 16777216\n",
            "        }\n",
            "        clear_multiplication_count: 16777216\n",
            "        clear_multiplication_count_per_parameter: {\n",
            "            LweSecretKeyParam(dimension=2117): 16777216\n",
            "        }\n",
            "        encrypted_negation_count: 0\n",
            "    }\n",
            "}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Computation Graph for _clear_forward_proxy\n",
            "--------------------------------------------------------------------------------\n",
            "%0 = _x                               # EncryptedTensor<int16, shape=(1, 4096)>        ∈ [-32768, 32767]\n",
            "%1 = [[65535    ...  0 65535]]        # ClearTensor<uint16, shape=(4096, 4096)>        ∈ [0, 65535]                       @ /fc/Gemm.matmul\n",
            "%2 = matmul(%0, %1)                   # EncryptedTensor<int32, shape=(1, 4096)>        ∈ [-2147450880, 2147385345]        @ /fc/Gemm.matmul\n",
            "return %2\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Bit-Width Constraints for _clear_forward_proxy\n",
            "--------------------------------------------------------------------------------\n",
            "%0:\n",
            "    _clear_forward_proxy.%0 >= 16\n",
            "%1:\n",
            "    _clear_forward_proxy.%1 >= 16\n",
            "%2:\n",
            "    _clear_forward_proxy.%2 >= 32\n",
            "    _clear_forward_proxy.%0 == _clear_forward_proxy.%1\n",
            "    _clear_forward_proxy.%1 == _clear_forward_proxy.%2\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Bit-Width Assignments for _clear_forward_proxy\n",
            "--------------------------------------------------------------------------------\n",
            " _clear_forward_proxy.%0 = 32\n",
            " _clear_forward_proxy.%1 = 32\n",
            " _clear_forward_proxy.%2 = 32\n",
            "_clear_forward_proxy.max = 32\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Bit-Width Assigned Computation Graph for _clear_forward_proxy\n",
            "--------------------------------------------------------------------------------\n",
            "%0 = _x                               # EncryptedTensor<int32, shape=(1, 4096)>        ∈ [-32768, 32767]\n",
            "%1 = [[65535    ...  0 65535]]        # ClearTensor<uint17, shape=(4096, 4096)>        ∈ [0, 65535]                       @ /fc/Gemm.matmul\n",
            "%2 = matmul(%0, %1)                   # EncryptedTensor<int32, shape=(1, 4096)>        ∈ [-2147450880, 2147385345]        @ /fc/Gemm.matmul\n",
            "return %2\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Optimizer\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Statistics\n",
            "--------------------------------------------------------------------------------\n",
            "size_of_secret_keys: 16936\n",
            "size_of_bootstrap_keys: 0\n",
            "size_of_keyswitch_keys: 0\n",
            "p_error: 0.000953489394558963\n",
            "global_p_error: 0.9799064350592518\n",
            "complexity: 2117.0\n",
            "functions: {\n",
            "    _clear_forward_proxy: {\n",
            "        size_of_inputs: 98304\n",
            "        size_of_outputs: 69402624\n",
            "        programmable_bootstrap_count: 0\n",
            "        key_switch_count: 0\n",
            "        packing_key_switch_count: 0\n",
            "        clear_addition_count: 0\n",
            "        encrypted_addition_count: 16777216\n",
            "        encrypted_addition_count_per_parameter: {\n",
            "            LweSecretKeyParam(dimension=2117): 16777216\n",
            "        }\n",
            "        clear_multiplication_count: 16777216\n",
            "        clear_multiplication_count_per_parameter: {\n",
            "            LweSecretKeyParam(dimension=2117): 16777216\n",
            "        }\n",
            "        encrypted_negation_count: 0\n",
            "    }\n",
            "}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "FHE model compilation took 45.22 seconds\n",
            "Key generation took 0.00 seconds\n",
            "FHE forward call took 58.2437 seconds\n",
            "FHE processed image saved as 'fhe_processed_sample.png'\n",
            "FHE Pipeline Quality Metrics (Four-Quadrant QIM Robust Evaluation, Original vs FHE Processed):\n",
            "  psnr: 41.84367228082698\n",
            "  ssim: 0.9949560613592418\n",
            "  watermark_accuracy: 99.93903189897537\n",
            "Results saved to 'watermarking_results.json'\n"
          ]
        }
      ]
    }
  ]
}